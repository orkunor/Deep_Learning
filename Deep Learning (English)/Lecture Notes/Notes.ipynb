{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a18c6c",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) \n",
    "\n",
    "ARTIFICIAL NEURAL NETWORKS: \n",
    "\n",
    "--NEURAL NETWORK USED TO BE RELATIVELY SLOW COMPARED TO OTHER MACHINE LEARNING METHODS, BUT NOW IT IS BEING USED MORE AND MORE WITH THE DEVELOPMENT OF COMPUTERS. \n",
    "\n",
    "--Input => SYSTEM f(x) => OUTPUT SHOWS THIS STRUCTURE !!!\n",
    "\n",
    "--THE NEURON IS OUR SYSTEM HERE \n",
    "\n",
    "--INPUTS ARE AGAIN INDEPENDENT VARIABLES AND OUTPUTS ARE DEPENDENT VARIABLES!!!\n",
    "\n",
    "--DATA SHOULD BE BETWEEN 0-1, WE STANDARDIZE \n",
    "\n",
    "-OUR OUTPUT SHOULD BE IN THE RANGE OF 0-1 IN GENERAL!!!\n",
    "\n",
    "-MULTIPLIED BY THE WEIGHTS OF OUR SYNAPSES, THE INCOMING SIGNAL WILL REACH THE SYSTEM FROM HERE, WHICH IS ALSO IMPORTANT \n",
    "\n",
    "--ACTIVATION FUNCTION IS THE FIRING POWER REQUIRED FOR THE NEURON TO MAKE A DECISION FOR THE SYSTEM TO WORK, IT MUST REACH A CERTAIN LIMIT IN ORDER TO FIRE \n",
    "\n",
    "--NEURAL NETWORKS FORM THE BASIS OF DEEP LEARNING.\n",
    "\n",
    "--FOR THE ACTIVATION FUNCTION, SOME FUNCTIONS ARE MORE PREFERRED \n",
    "\n",
    "--FOR EXAMPLE, THERE IS A CYGMOID FUNCTION, WHICH WE ALSO EXAMINED IN THE LOGISTIC REGRESSION\n",
    "\n",
    "--THRESHOLD FUNCTION IS ALSO USED A LOT, THE REASON IT IS USED HERE IS THAT WHEN THE ACTIVATION VALUE IS EXCEEDED, THE VALUE SUDDENLY BECOMES 1.\n",
    "\n",
    "--SIGMOID CAN RETURN AN INTERMEDIATE VALUE WITH THE FUNCTION \n",
    "\n",
    "CAN BE USED IN --TANH...\n",
    "\n",
    "# WHAT IS A LAYER IN ARTIFICIAL NEURAL NETWORKS? (LAYER)\n",
    "\n",
    "--INPUT LAYER, HIDDEN LAYER, OUTPUT LAYER \n",
    "\n",
    "-- THE HIDDEN LAYER IS THE LAYER OUTSIDE THE PART THAT WE CAN INTERVENE IN, I.E. THE LAYER THAT WE CANNOT INTERVENE IN. \n",
    "\n",
    "-- ACTIVATION WITH WEIGHTS IS ALSO VALID HERE, WHETHER IT FIRES A SIGNAL OR NOT DEPENDS ON THE ACTIVATION FUNCTION \n",
    "\n",
    "-- WE DON'T HAVE TO USE THE SAME FUNCTION IN EVERY NEURON, WE CAN DO IT DIFFERENTLY. \n",
    "\n",
    "--THINK OF IT AS HAVING DIFFERENT LAYERS.  \n",
    "\n",
    "-- FOR EACH LEVEL OF PERCEPTION, DIFFERENT PARTICIPANTS CAN BE SET UP \n",
    "\n",
    "THINK --AND GATE IS ONLY TRUE WHEN BOTH ARE 1 \n",
    "\n",
    "WE ALSO MADE AN EXAMPLE TO UNDERSTAND USING --OR GATE \n",
    "\n",
    "--XOR GATE \n",
    "\n",
    "--INTRODUCING THE NOTION OF THE LINEARLY SEPARABLE \n",
    "\n",
    "# HOW DOES ANN LEARN? THE CONCEPT OF PERCEPTRON (PERCEIVER). \n",
    "\n",
    "-- HEIGHT AND WEIGHT ARE MULTIPLIED BY DIFFERENT WEIGHTS TO CREATE A FORMULA AND THE NEURON TRIES TO FIND THE GENDER AND ACCORDINGLY THE ACTIVATION VALUE IS DETERMINED !!!\n",
    "\n",
    "--LEARNING HAS MANY PARAMETERS \n",
    "\n",
    "--W1,W2 AND THERSHOLD ARE 3 DIFFERENT THINGS TO LEARN FOR A SINGLE NEURON\n",
    "\n",
    "--PERCEPTRON COMES INTO PLAY HERE \n",
    "\n",
    "--AGAIN WE WILL DIVIDE OUR DATA INTO TRAINING AND TEST SET \n",
    "\n",
    "--PERCEPTRON HERE PROVIDES FEEDBACK TO DETERMINE THE CORRECT VALUES OF W1,W2 !!!\n",
    "\n",
    "--C = 1/2(ACTUAL-ESTIMATED)^2 SO THE PERCEPTRON FINDS THE VALUE OF C AND SENDS IT IN THE FEEDBACK DIRECTION AND UPDATES IT FOR W1,W2 \n",
    "\n",
    "-- THE MACHINE WILL TRAIN AND IMPROVE ITSELF OVER TIME \n",
    "\n",
    "--EVEN IF IT'S A VERY BAD ALGORITHM, THE SYSTEM WILL IMPROVE ITSELF \n",
    "\n",
    "CONSIDER --C AS A PUNISHMENT HERE \n",
    "\n",
    "# GRADIENT DESCENDENT : \n",
    "\n",
    "--WE MOVE FORWARD LOOKING FOR THE OPTIMUM POINT.\n",
    "\n",
    "--LOOKING FOR THE MOST ACCURATE POINT THAT WILL NO LONGER MOVE \n",
    "\n",
    "# STOCHASTIC GRADIENT DESCENDENT : \n",
    "\n",
    "--GRADIENT DESCENDENT CAN CAPTURE A LOCAL OPTIMUM AND SELECT IT, WHEREAS WE CAN SELECT AT OTHER LOCAL POINTS AND MISS IT, SO WE USE DIFFERENT APPROACHES \n",
    "\n",
    "-- STOCHASTIC IS A METHOD BASED ON THE EXAMPLE, WE DO IT STEP BY STEP \n",
    "\n",
    "--BATCH APPROACH LOOKS AT THE WHOLE BATCH AND FEEDS BACK TO THE SYSTEM. IT IS A BIT DIFFICULT IF THERE IS A LOT OF DATA \n",
    "\n",
    "-- THE MINI BATCH APPROACH DIVIDES BATCHES INTO SMALL BATCHES \n",
    "\n",
    "\n",
    "# BACKPROPAGATION: \n",
    "\n",
    "--THERE ARE 2 TYPES OF PROPAGATION ON THE ARTIFICIAL NEURAL NETWORK, ONE IS THE FORWARD PROPAGATION PHASE FROM INPUT TO OUTPUT \n",
    "\n",
    "--THERE IS ALSO PROPAGATION FROM EXIT TO ENTRY, AND THERE IS ALSO BIDIRECTIONAL PROPAGATION \n",
    "\n",
    "--STEP 1: INITIALIZE THE WHOLE NETWORK WITH RANDOM NUMBERS (CLOSE TO ZERO BUT DIFFERENT FROM ZERO). \n",
    "\n",
    "--STEP 2 : THE FIRST ROW FROM THE DATA SET (ONE NEURON PER ATTRIBUTE) IS GIVEN FROM THE INPUT LAYER \n",
    "\n",
    "--NOTE : NEURAL NETWORKS ARE IMMUNE TO DUMMY VARIABLES !!! NO MATTER HOW MUCH YOU GIVE IT, IT DOES THE ATTRIBUTE EXTRACTION ITSELF... THE NEURAL NETWORK CAN DO THE PREPROCESSING ITSELF... GIVE IT ENOUGH NEURONS  \n",
    "\n",
    "--STEP 3: BY FORWARD PROPAGATION, THE ANN (ARTIFICIAL NEURAL NETWORK) IS UPDATED UNTIL IT GIVES THE DESIRED RESULT. \n",
    "\n",
    "--STEP 4: ERROR IS CALCULATED BY TAKING THE DIFFERENCE BETWEEN THE ACTUAL AND THE OUTPUT... \n",
    "\n",
    "--STEP 5: BY BACK PROPAGATION, THE WEIGHT ON EACH SYNAPSES IS CHANGED BY THE AMOUNT RESPONSIBLE FOR THE ERROR. THE AMOUNT OF MODIFICATION ALSO DEPENDS ON THE LEARNING RATE \n",
    "\n",
    "--STEP 6: UPDATE STEPS 1-5 UNTIL YOU GET THE DESIRED RESULT (REINFORCED LEARNING) OR UPDATE ALL THE AVAILABLE DATA AT ONCE AFTER RUNNING THEM ON THE NETWORK OF INTEREST (BATCH LEARNING). \n",
    "\n",
    "--STEP 7: ONCE THE ENTIRE TRAINING SET HAS BEEN RUN, THE EPOCH IS COMPLETE. REPEAT THE EPOCH USING THE SAME DATASETS. WE NEED TO GIVE THE EPOCH VALUE CORRECTLY BECAUSE IF WE GIVE TOO MUCH, IT WILL WORK IN VAIN, IF WE GIVE LESS, IT WILL NOT LEARN CORRECTLY... \n",
    "\n",
    "--LEARININ RATE: IS THE SPEED AT WHICH IT WILL LEARN \n",
    "\n",
    "--EPOCH : HOW MANY TURNS IT WILL MAKE ON THE DATA... \n",
    "\n",
    "\n",
    "# DEEP LEARNING LIBRARIES : \n",
    "\n",
    "--PYTORCH IS ONE OF THE NEWLY ADDED LIBRARIES \n",
    "\n",
    "--SCISSORS ARE TOP CLASS, CAN USE TENSORFLOW BELOW... \n",
    "\n",
    "--GPU'S ARE VERY ADVANTAGEOUS WHEN DEEP LEARNING IS USED AND THERE ARE MANY NEURONS ON IT \n",
    "\n",
    "--GPU'S ARE USED TO VISUALIZE GRAPHICS AND DEEP LEARNING IS VERY USEFUL BECAUSE IT WORKS WITH THEM... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
